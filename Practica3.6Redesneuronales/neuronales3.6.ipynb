{"cells":[{"cell_type":"markdown","metadata":{},"source":["Desarrollador: Jonathan Emmanuel Hernandez Ortiz\n","Clasificación de Dígitos Escritos a Mano con Redes Neuronales (MNIST)\n","Objetivo: Desarrollar un modelo de red neuronal que pueda clasificar imágenes de dígitos escritos a mano (del 0 al 9) con alta precisión utilizando el conjunto de datos MNIST.\n","\n","Descripción del Conjunto de Datos:\n","\n","MNIST es un conjunto de datos estándar que contiene 70,000 imágenes de dígitos escritos a mano: 60,000 para entrenamiento y 10,000 para pruebas.\n","Cada imagen tiene un tamaño de 28x28 píxeles y está en escala de grises."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten\n","from tensorflow.keras.utils import to_categorical"]},{"cell_type":"markdown","metadata":{},"source":["Cargar el conjunto de datos MNIST"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{},"source":["Preprocesamiento: normalizar las imÃ¡genes (escala 0-1)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["train_images = train_images / 255.0\n","test_images = test_images / 255.0"]},{"cell_type":"markdown","metadata":{},"source":["Convertir las etiquetas a formato one-hot"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)"]},{"cell_type":"markdown","metadata":{},"source":["Definir el modelo de red neuronal"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\ingjo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]}],"source":["model = Sequential([\n","    Flatten(input_shape=(28, 28)),  # Aplanar las imÃ¡genes 28x28 en un vector de 784 elementos\n","    Dense(128, activation='relu'),  # Capa oculta con 128 neuronas y funciÃ³n de activaciÃ³n ReLU\n","    Dense(10, activation='softmax')  # Capa de salida con 10 neuronas (una por cada dÃ­gito)\n","])"]},{"cell_type":"markdown","metadata":{},"source":["Compilar el modelo"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{},"source":["Entrenar el modelo"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8817 - loss: 0.4267\n","Epoch 2/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9637 - loss: 0.1238\n","Epoch 3/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9771 - loss: 0.0774\n","Epoch 4/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0568\n","Epoch 5/5\n","\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9867 - loss: 0.0436\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x179122d20a0>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["model.fit(train_images, train_labels, epochs=5, batch_size=32)"]},{"cell_type":"markdown","metadata":{},"source":["Evaluar el modelo en los datos de prueba"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9726 - loss: 0.0876\n","\n","PrecisiÃ³n en los datos de prueba: 97.6900%\n","\n"]}],"source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","test_acc_por= test_acc * 100\n","print(f\"\\nPrecisiÃ³n en los datos de prueba: {test_acc_por:.4f}%\\n\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":2}
